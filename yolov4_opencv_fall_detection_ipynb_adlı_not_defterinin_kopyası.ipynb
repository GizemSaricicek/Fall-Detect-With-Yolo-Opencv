{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/GizemSaricicek/Fall-Detect-on-With-Yolo-Opencv/blob/main/yolov4_opencv_fall_detection_ipynb_adl%C4%B1_not_defterinin_kopyas%C4%B1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zL5bquD-LS43"
      },
      "source": [
        "# YOLOv4 Object Detection with OpenCV and Python"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8wuq6Hktf5fe",
        "outputId": "d14fad1c-cbe0-4aba-fa8f-32f80d7a1afa"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.7/dist-packages (4.1.2.30)\n",
            "Collecting opencv-python\n",
            "  Downloading opencv_python-4.5.5.64-cp36-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (60.5 MB)\n",
            "\u001b[K     |████████████████████████████████| 60.5 MB 57 kB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.14.5 in /usr/local/lib/python3.7/dist-packages (from opencv-python) (1.21.5)\n",
            "Installing collected packages: opencv-python\n",
            "  Attempting uninstall: opencv-python\n",
            "    Found existing installation: opencv-python 4.1.2.30\n",
            "    Uninstalling opencv-python-4.1.2.30:\n",
            "      Successfully uninstalled opencv-python-4.1.2.30\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "albumentations 0.1.12 requires imgaug<0.2.7,>=0.2.5, but you have imgaug 0.2.9 which is incompatible.\u001b[0m\n",
            "Successfully installed opencv-python-4.5.5.64\n"
          ]
        }
      ],
      "source": [
        "# upgrade opencv to the latest version\n",
        "! pip install --upgrade opencv-python"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pZrK8fU8Em2i"
      },
      "outputs": [],
      "source": [
        "# import necessary packages\n",
        "import cv2\n",
        "import numpy as np\n",
        "from google.colab.patches import cv2_imshow"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UjX_AusQFPlP",
        "outputId": "94b16632-e7ee-480e-d6a3-741156a35b5f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2022-04-04 07:50:23--  https://github.com/AlexeyAB/darknet/releases/download/darknet_yolo_v3_optimal/yolov4.weights\n",
            "Resolving github.com (github.com)... 13.114.40.48\n",
            "Connecting to github.com (github.com)|13.114.40.48|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://objects.githubusercontent.com/github-production-release-asset-2e65be/75388965/ba4b6380-889c-11ea-9751-f994f5961796?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAIWNJYAX4CSVEH53A%2F20220404%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20220404T075024Z&X-Amz-Expires=300&X-Amz-Signature=4dd719eaac112b67e5113ed887125a7b1621603db98171c4c9865d04d31d69d5&X-Amz-SignedHeaders=host&actor_id=0&key_id=0&repo_id=75388965&response-content-disposition=attachment%3B%20filename%3Dyolov4.weights&response-content-type=application%2Foctet-stream [following]\n",
            "--2022-04-04 07:50:24--  https://objects.githubusercontent.com/github-production-release-asset-2e65be/75388965/ba4b6380-889c-11ea-9751-f994f5961796?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAIWNJYAX4CSVEH53A%2F20220404%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20220404T075024Z&X-Amz-Expires=300&X-Amz-Signature=4dd719eaac112b67e5113ed887125a7b1621603db98171c4c9865d04d31d69d5&X-Amz-SignedHeaders=host&actor_id=0&key_id=0&repo_id=75388965&response-content-disposition=attachment%3B%20filename%3Dyolov4.weights&response-content-type=application%2Foctet-stream\n",
            "Resolving objects.githubusercontent.com (objects.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to objects.githubusercontent.com (objects.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 257717640 (246M) [application/octet-stream]\n",
            "Saving to: ‘yolov4.weights’\n",
            "\n",
            "yolov4.weights      100%[===================>] 245.78M  6.14MB/s    in 29s     \n",
            "\n",
            "2022-04-04 07:50:53 (8.52 MB/s) - ‘yolov4.weights’ saved [257717640/257717640]\n",
            "\n",
            "--2022-04-04 07:50:53--  https://github.com/arunponnusamy/object-detection-opencv/releases/download/v0.1/yolov4.cfg\n",
            "Resolving github.com (github.com)... 13.114.40.48\n",
            "Connecting to github.com (github.com)|13.114.40.48|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://objects.githubusercontent.com/github-production-release-asset-2e65be/141098229/def74a00-3e31-11eb-95a1-afc24499e0ee?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAIWNJYAX4CSVEH53A%2F20220404%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20220404T075053Z&X-Amz-Expires=300&X-Amz-Signature=bbb7b895453d709f2549c74e0d5444bb8a3ea44c36ef727df2aa1b417bf3349c&X-Amz-SignedHeaders=host&actor_id=0&key_id=0&repo_id=141098229&response-content-disposition=attachment%3B%20filename%3Dyolov4.cfg&response-content-type=application%2Foctet-stream [following]\n",
            "--2022-04-04 07:50:54--  https://objects.githubusercontent.com/github-production-release-asset-2e65be/141098229/def74a00-3e31-11eb-95a1-afc24499e0ee?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAIWNJYAX4CSVEH53A%2F20220404%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20220404T075053Z&X-Amz-Expires=300&X-Amz-Signature=bbb7b895453d709f2549c74e0d5444bb8a3ea44c36ef727df2aa1b417bf3349c&X-Amz-SignedHeaders=host&actor_id=0&key_id=0&repo_id=141098229&response-content-disposition=attachment%3B%20filename%3Dyolov4.cfg&response-content-type=application%2Foctet-stream\n",
            "Resolving objects.githubusercontent.com (objects.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to objects.githubusercontent.com (objects.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 12230 (12K) [application/octet-stream]\n",
            "Saving to: ‘yolov4.cfg’\n",
            "\n",
            "yolov4.cfg          100%[===================>]  11.94K  --.-KB/s    in 0.001s  \n",
            "\n",
            "2022-04-04 07:50:54 (21.1 MB/s) - ‘yolov4.cfg’ saved [12230/12230]\n",
            "\n",
            "--2022-04-04 07:50:54--  https://github.com/arunponnusamy/object-detection-opencv/releases/download/v0.1/coco_class_names.txt\n",
            "Resolving github.com (github.com)... 13.114.40.48\n",
            "Connecting to github.com (github.com)|13.114.40.48|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://objects.githubusercontent.com/github-production-release-asset-2e65be/141098229/e159a400-3e31-11eb-804c-f412d02e7175?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAIWNJYAX4CSVEH53A%2F20220404%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20220404T075054Z&X-Amz-Expires=300&X-Amz-Signature=c2966f5f0f3df4e3b76552541d856e2a850584179513209fa11eb1cafe4a0d00&X-Amz-SignedHeaders=host&actor_id=0&key_id=0&repo_id=141098229&response-content-disposition=attachment%3B%20filename%3Dcoco_class_names.txt&response-content-type=application%2Foctet-stream [following]\n",
            "--2022-04-04 07:50:54--  https://objects.githubusercontent.com/github-production-release-asset-2e65be/141098229/e159a400-3e31-11eb-804c-f412d02e7175?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAIWNJYAX4CSVEH53A%2F20220404%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20220404T075054Z&X-Amz-Expires=300&X-Amz-Signature=c2966f5f0f3df4e3b76552541d856e2a850584179513209fa11eb1cafe4a0d00&X-Amz-SignedHeaders=host&actor_id=0&key_id=0&repo_id=141098229&response-content-disposition=attachment%3B%20filename%3Dcoco_class_names.txt&response-content-type=application%2Foctet-stream\n",
            "Resolving objects.githubusercontent.com (objects.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to objects.githubusercontent.com (objects.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 620 [application/octet-stream]\n",
            "Saving to: ‘coco_class_names.txt’\n",
            "\n",
            "coco_class_names.tx 100%[===================>]     620  --.-KB/s    in 0s      \n",
            "\n",
            "2022-04-04 07:50:55 (33.4 MB/s) - ‘coco_class_names.txt’ saved [620/620]\n",
            "\n",
            "--2022-04-04 07:50:55--  https://github.com/arunponnusamy/object-detection-opencv/releases/download/v0.1/dog.jpg\n",
            "Resolving github.com (github.com)... 13.114.40.48\n",
            "Connecting to github.com (github.com)|13.114.40.48|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://objects.githubusercontent.com/github-production-release-asset-2e65be/141098229/a9536080-3e33-11eb-986e-901132ae2291?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAIWNJYAX4CSVEH53A%2F20220404%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20220404T075055Z&X-Amz-Expires=300&X-Amz-Signature=9c28d9b3525ff76663ab8254e124472adb9b5ba83737576603b29e7bde8b57ec&X-Amz-SignedHeaders=host&actor_id=0&key_id=0&repo_id=141098229&response-content-disposition=attachment%3B%20filename%3Ddog.jpg&response-content-type=application%2Foctet-stream [following]\n",
            "--2022-04-04 07:50:55--  https://objects.githubusercontent.com/github-production-release-asset-2e65be/141098229/a9536080-3e33-11eb-986e-901132ae2291?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAIWNJYAX4CSVEH53A%2F20220404%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20220404T075055Z&X-Amz-Expires=300&X-Amz-Signature=9c28d9b3525ff76663ab8254e124472adb9b5ba83737576603b29e7bde8b57ec&X-Amz-SignedHeaders=host&actor_id=0&key_id=0&repo_id=141098229&response-content-disposition=attachment%3B%20filename%3Ddog.jpg&response-content-type=application%2Foctet-stream\n",
            "Resolving objects.githubusercontent.com (objects.githubusercontent.com)... 185.199.110.133, 185.199.111.133, 185.199.109.133, ...\n",
            "Connecting to objects.githubusercontent.com (objects.githubusercontent.com)|185.199.110.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 163759 (160K) [application/octet-stream]\n",
            "Saving to: ‘dog.jpg’\n",
            "\n",
            "dog.jpg             100%[===================>] 159.92K  --.-KB/s    in 0.03s   \n",
            "\n",
            "2022-04-04 07:50:56 (5.78 MB/s) - ‘dog.jpg’ saved [163759/163759]\n",
            "\n",
            "--2022-04-04 07:50:56--  https://github.com/arunponnusamy/object-detection-opencv/releases/download/v0.1/sample_input.mp4\n",
            "Resolving github.com (github.com)... 13.114.40.48\n",
            "Connecting to github.com (github.com)|13.114.40.48|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://objects.githubusercontent.com/github-production-release-asset-2e65be/141098229/68f2e300-3e31-11eb-847a-14b4b2119ccb?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAIWNJYAX4CSVEH53A%2F20220404%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20220404T075056Z&X-Amz-Expires=300&X-Amz-Signature=3aecc12f7a85d04065e925a82ba93b0e138e62bd55c044abe0c6f9d04fbf98a0&X-Amz-SignedHeaders=host&actor_id=0&key_id=0&repo_id=141098229&response-content-disposition=attachment%3B%20filename%3Dsample_input.mp4&response-content-type=application%2Foctet-stream [following]\n",
            "--2022-04-04 07:50:56--  https://objects.githubusercontent.com/github-production-release-asset-2e65be/141098229/68f2e300-3e31-11eb-847a-14b4b2119ccb?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAIWNJYAX4CSVEH53A%2F20220404%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20220404T075056Z&X-Amz-Expires=300&X-Amz-Signature=3aecc12f7a85d04065e925a82ba93b0e138e62bd55c044abe0c6f9d04fbf98a0&X-Amz-SignedHeaders=host&actor_id=0&key_id=0&repo_id=141098229&response-content-disposition=attachment%3B%20filename%3Dsample_input.mp4&response-content-type=application%2Foctet-stream\n",
            "Resolving objects.githubusercontent.com (objects.githubusercontent.com)... 185.199.111.133, 185.199.110.133, 185.199.108.133, ...\n",
            "Connecting to objects.githubusercontent.com (objects.githubusercontent.com)|185.199.111.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 662629 (647K) [application/octet-stream]\n",
            "Saving to: ‘sample_input.mp4’\n",
            "\n",
            "sample_input.mp4    100%[===================>] 647.10K  --.-KB/s    in 0.05s   \n",
            "\n",
            "2022-04-04 07:50:57 (11.7 MB/s) - ‘sample_input.mp4’ saved [662629/662629]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# download necessary files for processing\n",
        "! wget https://github.com/AlexeyAB/darknet/releases/download/darknet_yolo_v3_optimal/yolov4.weights\n",
        "! wget https://github.com/arunponnusamy/object-detection-opencv/releases/download/v0.1/yolov4.cfg\n",
        "! wget https://github.com/arunponnusamy/object-detection-opencv/releases/download/v0.1/coco_class_names.txt\n",
        "! wget https://github.com/arunponnusamy/object-detection-opencv/releases/download/v0.1/dog.jpg\n",
        "! wget https://github.com/arunponnusamy/object-detection-opencv/releases/download/v0.1/sample_input.mp4"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XR7bZ1gwHNlJ"
      },
      "outputs": [],
      "source": [
        "# read object category list\n",
        "with open('coco_class_names.txt', 'r') as f:\n",
        "    classes = [line.strip() for line in f.readlines()]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_EE0lrdOfV58"
      },
      "outputs": [],
      "source": [
        "# create random color to draw for each class \n",
        "#COLORS = np.random.uniform(0, 255, size=(len(classes), 3))\n",
        "COLORS = np.random.uniform(0, 255, size=(255, 3)) #tek renk"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I_-d8hmzffGu"
      },
      "outputs": [],
      "source": [
        "# load model\n",
        "net = cv2.dnn.readNet('yolov4.weights', 'yolov4.cfg')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8OqSbrMhftuw"
      },
      "outputs": [],
      "source": [
        "# get the output layers from YOLO architecture for reading output predictions\n",
        "def get_output_layers(net):\n",
        "    layer_names = net.getLayerNames()\n",
        "    output_layers = [layer_names[i - 1] for i in net.getUnconnectedOutLayers()]\n",
        "    return output_layers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-1dSwirDf2M8"
      },
      "outputs": [],
      "source": [
        "# helper function for drawing bounding boxes\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "def draw_prediction(img, class_id, confidence, x, y, x_plus_w, y_plus_h):\n",
        "    label = \"DUSME YOK\"\n",
        "    color = COLORS[class_id]\n",
        "    #sns.color_palette(\"inferno\", 7)\n",
        "    cv2.rectangle(img, (x,y), (x_plus_w,y_plus_h), color, 2)\n",
        "    cv2.putText(img, label, (x-10,y-10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, color, 2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dNqUAgD2vLxI"
      },
      "outputs": [],
      "source": [
        "def draw_fall(img, confidence, x, y, x_plus_w, y_plus_h):\n",
        "    label = \"DUSME TESPIT EDILDI\"\n",
        "    color = np.random.uniform(255, 255, size=(0, 3))\n",
        "    cv2.rectangle(img, (x,y), (x_plus_w,y_plus_h), color, 2)\n",
        "    cv2.putText(img, label, (x-10,y-10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, color, 2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dihDxpp_hOiK"
      },
      "outputs": [],
      "source": [
        "# dusme icin default degerler tanımlama\n",
        "\n",
        "fall = 0 # kontrol icin\n",
        "trashold = 0 # esik\n",
        "pastRatio = 0 # onceki person oranı\n",
        "result = 0 # sonuc\n",
        "# Instantiate results array\n",
        "resultsList = [] # oran artışında 1, azalışında 0 atmak için List oluşturdum\n",
        "#first_center_y = 0\n",
        "#first_center_x = 0\n",
        "#frame_center = 0\n",
        "frame_w = 0\n",
        "frame_h = 0\n",
        "\n",
        "counter = 0\n",
        "\n",
        "# running inference on input frame\n",
        "\n",
        "def run_inference_Fall_Detection(image):\n",
        "    \n",
        "    # HUMAN DETECTION İLE İLGİLİ KODLAR\n",
        "\n",
        "    Width = image.shape[1]\n",
        "    Height = image.shape[0]\n",
        "    scale = 0.00392\n",
        "\n",
        "    blob = cv2.dnn.blobFromImage(image, scale, (416,416), (0,0,0), True, crop=False)\n",
        "\n",
        "    net.setInput(blob)\n",
        "\n",
        "    outs = net.forward(get_output_layers(net))\n",
        "\n",
        "    class_ids = []\n",
        "    confidences = []\n",
        "    boxes = []\n",
        "    results = []\n",
        "    conf_threshold = 0.5\n",
        "    nms_threshold = 0.4\n",
        "\n",
        "\n",
        "    for out in outs:\n",
        "\n",
        "        for detection in out:\n",
        "\n",
        "            #global first_center_x\n",
        "            #global first_center_y\n",
        "           \n",
        "            scores = detection[5:]\n",
        "            class_id = np.argmax(scores)\n",
        "            confidence = scores[class_id]\n",
        "            if confidence > 0.5:\n",
        "                center_x = int(detection[0] * Width)\n",
        "                center_y = int(detection[1] * Height)\n",
        "                w = int(detection[2] * Width)\n",
        "                h = int(detection[3] * Height)\n",
        "                x = center_x - w / 2\n",
        "                y = center_y - h / 2\n",
        "\n",
        "                #if(first_center_y == 0):\n",
        "                  #first_center_y = y+h/2\n",
        "\n",
        "                #if(first_center_x == 0):\n",
        "                  #first_center_x = x+w/2\n",
        "\n",
        "                class_ids.append(class_id)\n",
        "                confidences.append(float(confidence))\n",
        "                boxes.append([x, y, w, h])\n",
        "\n",
        "\n",
        "    indices = cv2.dnn.NMSBoxes(boxes, confidences, conf_threshold, nms_threshold)\n",
        "\n",
        "    for i in indices:\n",
        "\n",
        "      if(classes[class_ids[i]] =='person'): #eğer detect edilen person ise onun verilerini alma ve kutu çizdirme\n",
        "        i = i\n",
        "        box = boxes[i]\n",
        "        x = box[0]\n",
        "        y = box[1]\n",
        "        w = box[2] # width\n",
        "        h = box[3] # height\n",
        "\n",
        "        print(\"[INFO] detected {} with bbox {}\".format(str(classes[class_ids[i]]),\n",
        "                                [[\"x: \",int(x),\"y: \",int(y)], [\"x+w:\", int(x+w),\"y+h:\", int(y+h)], \" w: \",w, \"h: \",h]))\n",
        "        draw_prediction(image, class_ids[i], confidences[i], int(x),\n",
        "                        int(y), int(x+w), int(y+h))\n",
        "        \n",
        "        \n",
        "        #FALL DETECTION CODES\n",
        "\n",
        "        #trashold hesaplama\n",
        "\n",
        "        global trashold # global degiskenin degeri degistirilecekse bu sekilde cagiriliyormus\n",
        "        if(trashold == 0):# ilk frame'de trashold'u alacak daha sonra 0 olmadığı için almayacak böylece sabit kalmış olacak.\n",
        "          trashold = h/w\n",
        "        print(\"trashold: \", trashold)\n",
        "\n",
        "        #ilk frame oranını alma\n",
        "\n",
        "        global pastRatio\n",
        "        if(pastRatio == 0):\n",
        "          pastRatio = w/h\n",
        "        print(\"onceki oran: \", pastRatio)\n",
        "\n",
        "        # o anki frame orani hesaplama\n",
        "\n",
        "        currentFrameRatio = w/h # o anki frame'in oranı\n",
        "        global fall   \n",
        "        global resultsList\n",
        "        global counter\n",
        "        #global frame_center\n",
        "\n",
        "        #frame'lerin oranlarını karsilastirma\n",
        "        if(pastRatio <= currentFrameRatio):\n",
        "          #if(trashold <= currentFrameRatio):\n",
        "          fall = 1\n",
        "          #resultsList.append(fall)\n",
        "          if(counter%5 == 0):\n",
        "            resultsList.append(currentFrameRatio)\n",
        " \n",
        "        else:\n",
        "          fall = 0\n",
        "          #resultsList.append(fall)\n",
        "          if(counter%5 == 0):\n",
        "            resultsList.append(currentFrameRatio)\n",
        "          \n",
        "        counter = counter + 1\n",
        "\n",
        "        pastRatio = currentFrameRatio # frame kaydırma gibi bir sey\n",
        "\n",
        "        print(\"suanki oran: \", currentFrameRatio)\n",
        "       \n",
        "        \n",
        "      global result # dusme tespiti sonucu\n",
        "      if(fall == 0):\n",
        "        result = 0 # dusmedi demek\n",
        "      else:\n",
        "        result = 1 # dustu demek\n",
        "        draw_fall(image, confidences[i], int(x),\n",
        "                      int(y), int(x+w), int(y+h))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vfKHnIIcis7b"
      },
      "source": [
        "# Detecting objects in video"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "DÜŞME VİDEOSU ÇEKMEK İÇİN"
      ],
      "metadata": {
        "id": "9usIxcHjZi-m"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ORGUUclSb6wa",
        "outputId": "59fb9c73-1094-4205-e891-069a2be80d52"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/\n",
            "Mounted at /content/gdrive\n"
          ]
        }
      ],
      "source": [
        "#drive'a bağlanma kodu\n",
        "%cd ..\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ensMDxy4cKlg"
      },
      "outputs": [],
      "source": [
        "# DÜŞME İÇİN\n",
        "%cp '/content/gdrive/My Drive/YoloFall/video1.mp4' /content/video1.mp4 #drive'dan video çektim\n",
        "\n",
        "# DÜŞME İÇİN\n",
        "# open input video file\n",
        "vidcap = cv2.VideoCapture('/content/video1.mp4')\n",
        "\n",
        "if not vidcap.isOpened():\n",
        "    print(\"[ERROR] Could not open video file\")\n",
        "\n",
        "# get video properties\n",
        "width = int(vidcap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
        "height = int(vidcap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
        "fps = int(vidcap.get(cv2.CAP_PROP_FPS))\n",
        "\n",
        "# DÜŞME İÇİN\n",
        "# create video writer for saving output video\n",
        "fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
        "writer = cv2.VideoWriter(\"fall_detection_video1.mp4\", fourcc, fps,\n",
        "                         (width,height))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "DÜŞMEME VİDEOSU ÇEKMKE İÇİN"
      ],
      "metadata": {
        "id": "RFd1dE4TZu1Y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#drive'a bağlanma kodu\n",
        "%cd ..\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FjYtZeGR-P_j",
        "outputId": "c0bccc71-c5e8-4103-f8ba-cf259f891873"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/\n",
            "Mounted at /content/gdrive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# DÜŞMEME İÇİN\n",
        "%cp '/content/gdrive/My Drive/YoloFall/video29.mp4' /content/video29.mp4 #drive'dan video çektim\n",
        "\n",
        "# DÜŞMEME İÇİN\n",
        "# open input video file\n",
        "vidcap = cv2.VideoCapture('/content/video29.mp4')\n",
        "\n",
        "if not vidcap.isOpened():\n",
        "    print(\"[ERROR] Could not open video file\")\n",
        "\n",
        "# get video properties\n",
        "width = int(vidcap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
        "height = int(vidcap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
        "fps = int(vidcap.get(cv2.CAP_PROP_FPS))\n",
        "\n",
        "# DÜŞMEME İÇİN\n",
        "# create video writer for saving output video\n",
        "fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
        "writer = cv2.VideoWriter(\"fall_detection_video29.mp4\", fourcc, fps,\n",
        "                         (width,height))"
      ],
      "metadata": {
        "id": "HiIeMYvVZDSZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "DÜŞME TESPİTİ\n"
      ],
      "metadata": {
        "id": "fDdIIZ_tHqMl"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VaQhCqzikPPK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b0999bed-4045-40fc-8161-1f3249a6dbba"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[INFO] Processing frame  0\n",
            "[INFO] Processing frame  1\n",
            "[INFO] Processing frame  2\n",
            "[INFO] detected person with bbox [['x: ', 654, 'y: ', 132], ['x+w:', 712, 'y+h:', 263], ' w: ', 58, 'h: ', 131]\n",
            "trashold:  1.811764705882353\n",
            "onceki oran:  2.772727272727273\n",
            "suanki oran:  0.44274809160305345\n",
            "[INFO] Processing frame  3\n",
            "[INFO] detected person with bbox [['x: ', 653, 'y: ', 143], ['x+w:', 713, 'y+h:', 273], ' w: ', 60, 'h: ', 130]\n",
            "trashold:  1.811764705882353\n",
            "onceki oran:  0.44274809160305345\n",
            "suanki oran:  0.46153846153846156\n",
            "[INFO] Processing frame  4\n",
            "[INFO] detected person with bbox [['x: ', 649, 'y: ', 143], ['x+w:', 712, 'y+h:', 273], ' w: ', 63, 'h: ', 130]\n",
            "trashold:  1.811764705882353\n",
            "onceki oran:  0.46153846153846156\n",
            "suanki oran:  0.4846153846153846\n",
            "[INFO] Processing frame  5\n",
            "[INFO] detected person with bbox [['x: ', 636, 'y: ', 146], ['x+w:', 711, 'y+h:', 272], ' w: ', 75, 'h: ', 126]\n",
            "trashold:  1.811764705882353\n",
            "onceki oran:  0.4846153846153846\n",
            "suanki oran:  0.5952380952380952\n",
            "[INFO] Processing frame  6\n",
            "[INFO] detected person with bbox [['x: ', 606, 'y: ', 141], ['x+w:', 713, 'y+h:', 269], ' w: ', 107, 'h: ', 128]\n",
            "trashold:  1.811764705882353\n",
            "onceki oran:  0.5952380952380952\n",
            "suanki oran:  0.8359375\n",
            "[INFO] Processing frame  7\n",
            "[INFO] detected person with bbox [['x: ', 594, 'y: ', 128], ['x+w:', 709, 'y+h:', 270], ' w: ', 115, 'h: ', 142]\n",
            "trashold:  1.811764705882353\n",
            "onceki oran:  0.8359375\n",
            "suanki oran:  0.8098591549295775\n",
            "[INFO] Processing frame  8\n",
            "[INFO] detected person with bbox [['x: ', 593, 'y: ', 112], ['x+w:', 703, 'y+h:', 270], ' w: ', 110, 'h: ', 158]\n",
            "trashold:  1.811764705882353\n",
            "onceki oran:  0.8098591549295775\n",
            "suanki oran:  0.6962025316455697\n",
            "[INFO] Processing frame  9\n",
            "[INFO] detected person with bbox [['x: ', 590, 'y: ', 107], ['x+w:', 691, 'y+h:', 270], ' w: ', 101, 'h: ', 163]\n",
            "trashold:  1.811764705882353\n",
            "onceki oran:  0.6962025316455697\n",
            "suanki oran:  0.6196319018404908\n",
            "[INFO] Processing frame  10\n",
            "[INFO] detected person with bbox [['x: ', 588, 'y: ', 102], ['x+w:', 684, 'y+h:', 274], ' w: ', 96, 'h: ', 172]\n",
            "trashold:  1.811764705882353\n",
            "onceki oran:  0.6196319018404908\n",
            "suanki oran:  0.5581395348837209\n",
            "[INFO] Processing frame  11\n",
            "[INFO] detected person with bbox [['x: ', 554, 'y: ', 102], ['x+w:', 671, 'y+h:', 270], ' w: ', 117, 'h: ', 168]\n",
            "trashold:  1.811764705882353\n",
            "onceki oran:  0.5581395348837209\n",
            "suanki oran:  0.6964285714285714\n",
            "[INFO] Processing frame  12\n",
            "[INFO] detected person with bbox [['x: ', 547, 'y: ', 97], ['x+w:', 657, 'y+h:', 267], ' w: ', 110, 'h: ', 170]\n",
            "trashold:  1.811764705882353\n",
            "onceki oran:  0.6964285714285714\n",
            "suanki oran:  0.6470588235294118\n",
            "[INFO] Processing frame  13\n",
            "[INFO] detected person with bbox [['x: ', 544, 'y: ', 92], ['x+w:', 645, 'y+h:', 270], ' w: ', 101, 'h: ', 178]\n",
            "trashold:  1.811764705882353\n",
            "onceki oran:  0.6470588235294118\n",
            "suanki oran:  0.5674157303370787\n",
            "[INFO] Processing frame  14\n",
            "[INFO] detected person with bbox [['x: ', 548, 'y: ', 88], ['x+w:', 631, 'y+h:', 264], ' w: ', 83, 'h: ', 176]\n",
            "trashold:  1.811764705882353\n",
            "onceki oran:  0.5674157303370787\n",
            "suanki oran:  0.4715909090909091\n",
            "[INFO] Processing frame  15\n",
            "[INFO] detected person with bbox [['x: ', 501, 'y: ', 85], ['x+w:', 626, 'y+h:', 266], ' w: ', 125, 'h: ', 181]\n",
            "trashold:  1.811764705882353\n",
            "onceki oran:  0.4715909090909091\n",
            "suanki oran:  0.6906077348066298\n",
            "[INFO] Processing frame  16\n",
            "[INFO] detected person with bbox [['x: ', 476, 'y: ', 86], ['x+w:', 594, 'y+h:', 268], ' w: ', 118, 'h: ', 182]\n",
            "trashold:  1.811764705882353\n",
            "onceki oran:  0.6906077348066298\n",
            "suanki oran:  0.6483516483516484\n",
            "[INFO] Processing frame  17\n",
            "[INFO] detected person with bbox [['x: ', 468, 'y: ', 76], ['x+w:', 579, 'y+h:', 266], ' w: ', 111, 'h: ', 190]\n",
            "trashold:  1.811764705882353\n",
            "onceki oran:  0.6483516483516484\n",
            "suanki oran:  0.5842105263157895\n",
            "[INFO] Processing frame  18\n",
            "[INFO] detected person with bbox [['x: ', 464, 'y: ', 75], ['x+w:', 560, 'y+h:', 247], ' w: ', 96, 'h: ', 172]\n",
            "trashold:  1.811764705882353\n",
            "onceki oran:  0.5842105263157895\n",
            "suanki oran:  0.5581395348837209\n",
            "[INFO] Processing frame  19\n",
            "[INFO] detected person with bbox [['x: ', 459, 'y: ', 70], ['x+w:', 542, 'y+h:', 241], ' w: ', 83, 'h: ', 171]\n",
            "trashold:  1.811764705882353\n",
            "onceki oran:  0.5581395348837209\n",
            "suanki oran:  0.4853801169590643\n",
            "[INFO] Processing frame  20\n",
            "[INFO] detected person with bbox [['x: ', 406, 'y: ', 66], ['x+w:', 522, 'y+h:', 241], ' w: ', 116, 'h: ', 175]\n",
            "trashold:  1.811764705882353\n",
            "onceki oran:  0.4853801169590643\n",
            "suanki oran:  0.6628571428571428\n",
            "[INFO] Processing frame  21\n",
            "[INFO] detected person with bbox [['x: ', 393, 'y: ', 65], ['x+w:', 508, 'y+h:', 241], ' w: ', 115, 'h: ', 176]\n",
            "trashold:  1.811764705882353\n",
            "onceki oran:  0.6628571428571428\n",
            "suanki oran:  0.6534090909090909\n",
            "[INFO] Processing frame  22\n",
            "[INFO] detected person with bbox [['x: ', 392, 'y: ', 62], ['x+w:', 485, 'y+h:', 237], ' w: ', 93, 'h: ', 175]\n",
            "trashold:  1.811764705882353\n",
            "onceki oran:  0.6534090909090909\n",
            "suanki oran:  0.5314285714285715\n",
            "[INFO] Processing frame  23\n",
            "[INFO] detected person with bbox [['x: ', 392, 'y: ', 53], ['x+w:', 461, 'y+h:', 238], ' w: ', 69, 'h: ', 185]\n",
            "trashold:  1.811764705882353\n",
            "onceki oran:  0.5314285714285715\n",
            "suanki oran:  0.372972972972973\n",
            "[INFO] Processing frame  24\n",
            "[INFO] detected person with bbox [['x: ', 341, 'y: ', 53], ['x+w:', 443, 'y+h:', 238], ' w: ', 102, 'h: ', 185]\n",
            "trashold:  1.811764705882353\n",
            "onceki oran:  0.372972972972973\n",
            "suanki oran:  0.5513513513513514\n",
            "[INFO] Processing frame  25\n",
            "[INFO] detected person with bbox [['x: ', 321, 'y: ', 52], ['x+w:', 430, 'y+h:', 239], ' w: ', 109, 'h: ', 187]\n",
            "trashold:  1.811764705882353\n",
            "onceki oran:  0.5513513513513514\n",
            "suanki oran:  0.5828877005347594\n",
            "[INFO] Processing frame  26\n",
            "[INFO] detected person with bbox [['x: ', 319, 'y: ', 41], ['x+w:', 421, 'y+h:', 243], ' w: ', 102, 'h: ', 202]\n",
            "trashold:  1.811764705882353\n",
            "onceki oran:  0.5828877005347594\n",
            "suanki oran:  0.504950495049505\n",
            "[INFO] Processing frame  27\n",
            "[INFO] detected person with bbox [['x: ', 320, 'y: ', 43], ['x+w:', 388, 'y+h:', 232], ' w: ', 68, 'h: ', 189]\n",
            "trashold:  1.811764705882353\n",
            "onceki oran:  0.504950495049505\n",
            "suanki oran:  0.35978835978835977\n",
            "[INFO] Processing frame  28\n",
            "[INFO] detected person with bbox [['x: ', 305, 'y: ', 42], ['x+w:', 368, 'y+h:', 229], ' w: ', 63, 'h: ', 187]\n",
            "trashold:  1.811764705882353\n",
            "onceki oran:  0.35978835978835977\n",
            "suanki oran:  0.33689839572192515\n",
            "[INFO] Processing frame  29\n",
            "[INFO] detected person with bbox [['x: ', 269, 'y: ', 47], ['x+w:', 358, 'y+h:', 229], ' w: ', 89, 'h: ', 182]\n",
            "trashold:  1.811764705882353\n",
            "onceki oran:  0.33689839572192515\n",
            "suanki oran:  0.489010989010989\n",
            "[INFO] Processing frame  30\n",
            "[INFO] detected person with bbox [['x: ', 265, 'y: ', 45], ['x+w:', 357, 'y+h:', 234], ' w: ', 92, 'h: ', 189]\n",
            "trashold:  1.811764705882353\n",
            "onceki oran:  0.489010989010989\n",
            "suanki oran:  0.48677248677248675\n",
            "[INFO] Processing frame  31\n",
            "[INFO] detected person with bbox [['x: ', 258, 'y: ', 46], ['x+w:', 344, 'y+h:', 240], ' w: ', 86, 'h: ', 194]\n",
            "trashold:  1.811764705882353\n",
            "onceki oran:  0.48677248677248675\n",
            "suanki oran:  0.44329896907216493\n",
            "[INFO] Processing frame  32\n",
            "[INFO] detected person with bbox [['x: ', 250, 'y: ', 51], ['x+w:', 309, 'y+h:', 232], ' w: ', 59, 'h: ', 181]\n",
            "trashold:  1.811764705882353\n",
            "onceki oran:  0.44329896907216493\n",
            "suanki oran:  0.3259668508287293\n",
            "[INFO] Processing frame  33\n",
            "[INFO] detected person with bbox [['x: ', 226, 'y: ', 53], ['x+w:', 295, 'y+h:', 236], ' w: ', 69, 'h: ', 183]\n",
            "trashold:  1.811764705882353\n",
            "onceki oran:  0.3259668508287293\n",
            "suanki oran:  0.3770491803278688\n",
            "[INFO] Processing frame  34\n",
            "[INFO] detected person with bbox [['x: ', 198, 'y: ', 53], ['x+w:', 289, 'y+h:', 249], ' w: ', 91, 'h: ', 196]\n",
            "trashold:  1.811764705882353\n",
            "onceki oran:  0.3770491803278688\n",
            "suanki oran:  0.4642857142857143\n",
            "[INFO] Processing frame  35\n",
            "[INFO] detected person with bbox [['x: ', 199, 'y: ', 59], ['x+w:', 289, 'y+h:', 259], ' w: ', 90, 'h: ', 200]\n",
            "trashold:  1.811764705882353\n",
            "onceki oran:  0.4642857142857143\n",
            "suanki oran:  0.45\n",
            "[INFO] Processing frame  36\n",
            "[INFO] detected person with bbox [['x: ', 169, 'y: ', 57], ['x+w:', 268, 'y+h:', 264], ' w: ', 99, 'h: ', 207]\n",
            "trashold:  1.811764705882353\n",
            "onceki oran:  0.45\n",
            "suanki oran:  0.4782608695652174\n",
            "[INFO] Processing frame  37\n",
            "[INFO] detected person with bbox [['x: ', 153, 'y: ', 61], ['x+w:', 244, 'y+h:', 258], ' w: ', 91, 'h: ', 197]\n",
            "trashold:  1.811764705882353\n",
            "onceki oran:  0.4782608695652174\n",
            "suanki oran:  0.4619289340101523\n",
            "[INFO] Processing frame  38\n",
            "[INFO] detected person with bbox [['x: ', 144, 'y: ', 62], ['x+w:', 236, 'y+h:', 293], ' w: ', 92, 'h: ', 231]\n",
            "trashold:  1.811764705882353\n",
            "onceki oran:  0.4619289340101523\n",
            "suanki oran:  0.39826839826839827\n",
            "[INFO] Processing frame  39\n",
            "[INFO] detected person with bbox [['x: ', 141, 'y: ', 70], ['x+w:', 230, 'y+h:', 312], ' w: ', 89, 'h: ', 242]\n",
            "trashold:  1.811764705882353\n",
            "onceki oran:  0.39826839826839827\n",
            "suanki oran:  0.3677685950413223\n",
            "[INFO] Processing frame  40\n",
            "[INFO] detected person with bbox [['x: ', 143, 'y: ', 77], ['x+w:', 229, 'y+h:', 314], ' w: ', 86, 'h: ', 237]\n",
            "trashold:  1.811764705882353\n",
            "onceki oran:  0.3677685950413223\n",
            "suanki oran:  0.3628691983122363\n",
            "[INFO] Processing frame  41\n",
            "[INFO] detected person with bbox [['x: ', 141, 'y: ', 83], ['x+w:', 228, 'y+h:', 316], ' w: ', 87, 'h: ', 233]\n",
            "trashold:  1.811764705882353\n",
            "onceki oran:  0.3628691983122363\n",
            "suanki oran:  0.37339055793991416\n",
            "[INFO] Processing frame  42\n",
            "[INFO] detected person with bbox [['x: ', 137, 'y: ', 84], ['x+w:', 225, 'y+h:', 316], ' w: ', 88, 'h: ', 232]\n",
            "trashold:  1.811764705882353\n",
            "onceki oran:  0.37339055793991416\n",
            "suanki oran:  0.3793103448275862\n"
          ]
        }
      ],
      "source": [
        "# DETECT ETME\n",
        "# loop through frames and apply detection\n",
        "frame_count = 0\n",
        "\n",
        "while vidcap.isOpened():\n",
        "\n",
        "  status, frame = vidcap.read()\n",
        "\n",
        "  if not status:\n",
        "    break\n",
        "    \n",
        "  if(frame_count%1==0):\n",
        "    \n",
        "    print(\"[INFO] Processing frame \", frame_count)\n",
        "    run_inference_Fall_Detection(frame)\n",
        "\n",
        "  writer.write(frame)\n",
        "  frame_count += 1"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# frame'lerin oranına bakarak oluşturulan liste'nin üzerinde size=5 olan window gezdirerek yeni bir list oluşturuyorum. -> reduce etmek için gibi bir şey \n",
        "# ORTALAMA ALARAK\n",
        "\n",
        "def sliding_window(liste): \n",
        "    \n",
        "    i = 0\n",
        "    t = 0\n",
        "    reduceList = []\n",
        "    temp = []\n",
        "    avg = 0\n",
        "    sum = 0\n",
        "\n",
        "    print(liste)\n",
        "\n",
        "    if len(liste) == 5:\n",
        "        return liste\n",
        "    \n",
        "    for i in range(len(liste) - 5 + 1): #5 -> window size\n",
        "        \n",
        "      temp = liste[i: i+5] \n",
        "      print(temp)\n",
        "        \n",
        "      while t <= len(temp)-1:\n",
        "\n",
        "        sum = sum + temp[t]\n",
        "        t = t+1\n",
        "\n",
        "      avg = sum /5\n",
        "      reduceList.append(avg)       \n",
        "      \n",
        "      t = 0\n",
        "      avg = 0\n",
        "      sum = 0\n",
        "\n",
        "\n",
        "    return reduceList\n",
        "         \n",
        "\n",
        "avgList = sliding_window(resultsList)\n",
        "\n",
        "print(\"ort alinmis list: \",avgList)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lz4DsDaaWLbX",
        "outputId": "f8129a99-dc29-47eb-931d-ea55f79405ff"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0.551948051948052, 0.7569060773480663, 0.3956043956043956, 0.32386363636363635, 0.585635359116022, 0.6342857142857142, 0.6484848484848484, 0.6405228758169934, 0.6011560693641619, 0.6149425287356322, 2.881818181818182, 0.46153846153846156, 0.6962025316455697, 0.5674157303370787, 0.5581395348837209, 0.372972972972973, 0.33689839572192515, 0.3770491803278688, 0.39826839826839827]\n",
            "[0.551948051948052, 0.7569060773480663, 0.3956043956043956, 0.32386363636363635, 0.585635359116022]\n",
            "[0.7569060773480663, 0.3956043956043956, 0.32386363636363635, 0.585635359116022, 0.6342857142857142]\n",
            "[0.3956043956043956, 0.32386363636363635, 0.585635359116022, 0.6342857142857142, 0.6484848484848484]\n",
            "[0.32386363636363635, 0.585635359116022, 0.6342857142857142, 0.6484848484848484, 0.6405228758169934]\n",
            "[0.585635359116022, 0.6342857142857142, 0.6484848484848484, 0.6405228758169934, 0.6011560693641619]\n",
            "[0.6342857142857142, 0.6484848484848484, 0.6405228758169934, 0.6011560693641619, 0.6149425287356322]\n",
            "[0.6484848484848484, 0.6405228758169934, 0.6011560693641619, 0.6149425287356322, 2.881818181818182]\n",
            "[0.6405228758169934, 0.6011560693641619, 0.6149425287356322, 2.881818181818182, 0.46153846153846156]\n",
            "[0.6011560693641619, 0.6149425287356322, 2.881818181818182, 0.46153846153846156, 0.6962025316455697]\n",
            "[0.6149425287356322, 2.881818181818182, 0.46153846153846156, 0.6962025316455697, 0.5674157303370787]\n",
            "[2.881818181818182, 0.46153846153846156, 0.6962025316455697, 0.5674157303370787, 0.5581395348837209]\n",
            "[0.46153846153846156, 0.6962025316455697, 0.5674157303370787, 0.5581395348837209, 0.372972972972973]\n",
            "[0.6962025316455697, 0.5674157303370787, 0.5581395348837209, 0.372972972972973, 0.33689839572192515]\n",
            "[0.5674157303370787, 0.5581395348837209, 0.372972972972973, 0.33689839572192515, 0.3770491803278688]\n",
            "[0.5581395348837209, 0.372972972972973, 0.33689839572192515, 0.3770491803278688, 0.39826839826839827]\n",
            "ort alinmis list:  [0.5227915040760345, 0.539259036543567, 0.5175747907709234, 0.5665584868134429, 0.622016973413548, 0.6278784073374701, 1.0773849008439638, 1.0399956234546863, 1.0511315546204014, 1.0443834868149848, 1.0330228880446026, 0.5312538462755608, 0.5063258331122535, 0.44249516284871326, 0.4086656964349772]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#YENİ 0 1 LIST OLUŞTURMA 5 frame'de 1 alarak\n",
        "endList = []\n",
        "m = 0\n",
        "\n",
        "while m < len(avgList)-1:\n",
        "  \n",
        "  if(avgList[m] < avgList[m + 1]):\n",
        "    endList.append(1)\n",
        "  else:\n",
        "    endList.append(0)\n",
        "  m = m+1"
      ],
      "metadata": {
        "id": "JKckaThsxRlK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "endList"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VnGzceGDSrFz",
        "outputId": "a51d9df7-7477-49b6-9993-566574ec897c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[1, 0, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0]"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ARDIŞIK EN UZUN SUB ARRAYI BULUYOR -> 1 SE DUSTU 0 SA DUSMEDİ \n",
        "\n",
        "# reduce edilmiş list'te en fazla ardışık giden 1 ve 0 ları buldum, hangisi büyükse ona göre çıkarım yaptım (1 büyükse düştü 0 büyükse düşmedi)\n",
        "\n",
        "subZero = 0\n",
        "subOne = 0\n",
        "\n",
        "first_element = endList[0]\n",
        "\n",
        "for elmn in endList:\n",
        "   if first_element != elmn:\n",
        "      arrayresult = 0\n",
        "      break\n",
        "   else:\n",
        "      arrayresult = 1\n",
        "      continue\n",
        "\n",
        "if arrayresult:\n",
        "  if(first_element == 1):\n",
        "    result = 1\n",
        "    print(\"dustu\", result)\n",
        "\n",
        "  else:\n",
        "    result = 0\n",
        "    print(\"dusmedi\", result)\n",
        "else:\n",
        "  from itertools import groupby\n",
        "  endList\n",
        "  subZero = len(max([list(group) for item, group in groupby(endList) if item == 0], key=len))\n",
        "  subOne = len(max([list(group) for item, group in groupby(endList) if item == 1], key=len))\n",
        "\n",
        "  #print(\"sıfır: \",subZero)\n",
        "  #print(\"bir: \", subOne)\n",
        "\n",
        "  if(subOne + 1 >= subZero):\n",
        "    result = 1\n",
        "    print(\"dustu\", result)\n",
        "\n",
        "  else:\n",
        "    result = 0\n",
        "    print(\"dusmedi\", result)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R79gzQgT0WSe",
        "outputId": "2f0985f9-3588-46f6-c54d-fdf57a9bc564"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "dusmedi 0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "87GwJZtwvTM0",
        "outputId": "a180d58e-8341-4609-e4bf-7e901b44e86b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bIv0MDaTvjMX"
      },
      "outputs": [],
      "source": [
        "from sqlalchemy import create_engine\n",
        "my_conn=create_engine(\"sqlite:////content/drive/MyDrive/Database/my_db/BitirmeProjesi.db\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U6QffqQgvxSa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a96beddc-fd55-4a4a-a514-e0c7b9d6b02b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "('category',)\n",
            "('subcategory',)\n",
            "('student',)\n",
            "('calisan',)\n",
            "('sqlite_autoindex_calisan_1',)\n",
            "('birey',)\n",
            "('sqlite_autoindex_birey_1',)\n",
            "('yakin',)\n",
            "('sqlite_autoindex_yakin_1',)\n",
            "('birey_yakin_iliskisi',)\n",
            "('sqlite_autoindex_birey_yakin_iliskisi_1',)\n",
            "('duygu_veri_analizi',)\n",
            "('sqlite_autoindex_duygu_veri_analizi_1',)\n",
            "('sqlite_sequence',)\n",
            "('dusme_veri_analizi',)\n"
          ]
        }
      ],
      "source": [
        "r_set = my_conn.execute(''' select name from sqlite_master ''')\n",
        "for row in r_set:\n",
        "  print(row)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SxVL-z372ZZQ",
        "outputId": "f6250112-0e98-4b57-cc8a-faf0518435da"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "No of Records added :  -1\n"
          ]
        }
      ],
      "source": [
        "from datetime import date\n",
        "from datetime import datetime\n",
        "from sqlalchemy.exc import SQLAlchemyError\n",
        "\n",
        "analyseDate = datetime.today().strftime('%Y-%m-%d')\n",
        "\n",
        "if(result == 1):\n",
        "  try:\n",
        "    insertQuery = \"\"\"INSERT INTO dusme_veri_analizi ('dusme_tarihi', 'birey_id')\n",
        "      VALUES (?,?);\"\"\"\n",
        "    \n",
        "    # insert the data into table\n",
        "    my_conn.execute(insertQuery, (analyseDate,\n",
        "                                  12345678910\n",
        "                                ))\n",
        "  except SQLAlchemyError as e:\n",
        "    #print(e)\n",
        "    error = str(e.__dict__['orig'])\n",
        "    print(error)\n",
        "  else:\n",
        "    print(\"No of Records added : \",r_set.rowcount)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3pIt_s75v5vx",
        "outputId": "679a9c39-8c7c-4253-e357-ec6365c26024"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(1, '2022-03-22', 12345678910)\n",
            "(2, '2022-03-22', 12345678910)\n",
            "(3, '2022-03-22', 12345678910)\n",
            "(4, '2022-03-22', 12345678910)\n",
            "(5, '2022-04-03', 12345678910)\n",
            "(6, '2022-04-03', 12345678910)\n",
            "(7, '2022-04-03', 12345678910)\n",
            "(8, '2022-04-03', 12345678910)\n",
            "(9, '2022-04-03', 12345678910)\n",
            "(10, '2022-04-04', 12345678910)\n"
          ]
        }
      ],
      "source": [
        "r_set = my_conn.execute('''select * from dusme_veri_analizi''');\n",
        "for row in r_set:\n",
        "    print(row)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yIG83mQPkoC-"
      },
      "outputs": [],
      "source": [
        "# release resources\n",
        "vidcap.release()\n",
        "writer.release()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-5_nHteB4QVA"
      },
      "outputs": [],
      "source": [
        "# sonuç videosu drive'a atılıyor.\n",
        "import json\n",
        "import requests\n",
        "headers = {\"Authorization\": \"Bearer ya29.A0ARrdaM-UY6CrQDEYx1URKJqIWoRkykNPbX9LMf2bAAi7d4xXoz7DDbaA4ea-g-BodAaHr5z-0Uwja2rYIAKfFlU_HNuyhxo-gQP9FtTTHqQ2KbnAuXrj3JwDevaVtl44G0np4WrpT7rpWw_BY_0ZIdo6gbdx\"}\n",
        "para = {\n",
        "    \"name\": \"detect.mp4\",\n",
        "    \"parents\": [\"1dvpXlbXhXmLKEJy-Nm8vGay5GXifUYTH\"]\n",
        "}\n",
        "files = {\n",
        "    'data': ('metadata', json.dumps(para), 'application/json; charset=UTF-8'),\n",
        "    'file': open(\"/object_detection_yolov4.mp4\", \"rb\")\n",
        "}\n",
        "r = requests.post(\n",
        "    \"https://www.googleapis.com/upload/drive/v3/files?uploadType=multipart\",\n",
        "    headers=headers,\n",
        "    files=files\n",
        ")\n",
        "print(r.text)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yXUk_ZMVpPpP"
      },
      "source": [
        "Saved output video can be found in the left side panel under \"Files\" section."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# DENEME 2\n",
        "\n",
        "# dusme icin default degerler tanımlama\n",
        "\n",
        "fall = 0 # kontrol icin\n",
        "pastRatio = 0 # onceki person oranı\n",
        "result = 0 # sonuc\n",
        "# Instantiate results array\n",
        "resultsList = [] # oran artışında 1, azalışında 0 atmak için List oluşturdum\n",
        "#first_center_y = 0\n",
        "#first_center_x = 0\n",
        "#frame_center = 0\n",
        "frame_w = 0\n",
        "frame_h = 0\n",
        "past_w = 0\n",
        "past_h = 0\n",
        "\n",
        "# running inference on input frame\n",
        "\n",
        "def run_inference_Fall_Detection(image):\n",
        "    \n",
        "    # HUMAN DETECTION İLE İLGİLİ KODLAR\n",
        "\n",
        "    Width = image.shape[1]\n",
        "    Height = image.shape[0]\n",
        "    scale = 0.00392\n",
        "\n",
        "    blob = cv2.dnn.blobFromImage(image, scale, (416,416), (0,0,0), True, crop=False)\n",
        "\n",
        "    net.setInput(blob)\n",
        "\n",
        "    outs = net.forward(get_output_layers(net))\n",
        "\n",
        "    class_ids = []\n",
        "    confidences = []\n",
        "    boxes = []\n",
        "    results = []\n",
        "    conf_threshold = 0.5\n",
        "    nms_threshold = 0.4\n",
        "\n",
        "\n",
        "    for out in outs:\n",
        "\n",
        "        for detection in out:\n",
        "           \n",
        "            scores = detection[5:]\n",
        "            class_id = np.argmax(scores)\n",
        "            confidence = scores[class_id]\n",
        "            if confidence > 0.5:\n",
        "                center_x = int(detection[0] * Width)\n",
        "                center_y = int(detection[1] * Height)\n",
        "                w = int(detection[2] * Width)\n",
        "                h = int(detection[3] * Height)\n",
        "                x = center_x - w / 2\n",
        "                y = center_y - h / 2\n",
        "\n",
        "                class_ids.append(class_id)\n",
        "                confidences.append(float(confidence))\n",
        "                boxes.append([x, y, w, h])\n",
        "\n",
        "\n",
        "    indices = cv2.dnn.NMSBoxes(boxes, confidences, conf_threshold, nms_threshold)\n",
        "\n",
        "    for i in indices:\n",
        "\n",
        "      if(classes[class_ids[i]] =='person'): #eğer detect edilen person ise onun verilerini alma ve kutu çizdirme\n",
        "        i = i\n",
        "        box = boxes[i]\n",
        "        x = box[0]\n",
        "        y = box[1]\n",
        "        w = box[2] # width\n",
        "        h = box[3] # height\n",
        "\n",
        "        print(\"[INFO] detected {} with bbox {}\".format(str(classes[class_ids[i]]),\n",
        "                                [[\"x: \",int(x),\"y: \",int(y)], [\"x+w:\", int(x+w),\"y+h:\", int(y+h)], \" w: \",w, \"h: \",h]))\n",
        "        draw_prediction(image, class_ids[i], confidences[i], int(x),\n",
        "                        int(y), int(x+w), int(y+h))\n",
        "        \n",
        "        \n",
        "        #FALL DETECTION CODES\n",
        "\n",
        "        #trashold hesaplama\n",
        "\n",
        "        #global trashold # global degiskenin degeri degistirilecekse bu sekilde cagiriliyormus\n",
        "        #if(trashold == 0):# ilk frame'de trashold'u alacak daha sonra 0 olmadığı için almayacak böylece sabit kalmış olacak.\n",
        "          #trashold = h/w\n",
        "        #print(\"trashold: \", trashold)\n",
        "\n",
        "        #ilk frame w ve h'sini alma\n",
        "\n",
        "        global past_w\n",
        "        if(past_w == 0):\n",
        "          past_w = w\n",
        "        print(\"onceki w: \", past_w)\n",
        "\n",
        "        global past_h\n",
        "        if(past_h == 0):\n",
        "          past_h = h\n",
        "        print(\"onceki h: \", past_h)\n",
        "\n",
        "        # o anki frame orani hesaplama\n",
        "\n",
        "        global fall   \n",
        "        global frame_h\n",
        "        global frame_w\n",
        "\n",
        "\n",
        "        #frame'lerin oranlarını karsilastirma\n",
        "        frame_h= h\n",
        "        frame_w= w\n",
        "\n",
        "        if(past_w*2  < w-past_w and past_h/2 <h-past_h):\n",
        "          fall = 1\n",
        "          \n",
        "        else:\n",
        "          fall = 0\n",
        "\n",
        "          \n",
        "        past_w = w\n",
        "        past_h = h\n",
        "        \n",
        "        print(\"suanki w: \", w,\"suanki h: \", h)\n",
        "        \n",
        "      global result # dusme tespiti sonucu\n",
        "      if(fall == 0):\n",
        "        result = 0 # dusmedi demek\n",
        "      else:\n",
        "        result = 1 # dustu demek\n",
        "        draw_fall(image, confidences[i], int(x),\n",
        "                      int(y), int(x+w), int(y+h))\n"
      ],
      "metadata": {
        "id": "FzMnrPvz4u5W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W_4ItYBW9d5C"
      },
      "outputs": [],
      "source": [
        "#! cat coco_class_names.txt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7vEt6ggg-vrf"
      },
      "outputs": [],
      "source": [
        "#! cat yolov4.cfg"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KHugVdHIhh2l"
      },
      "outputs": [],
      "source": [
        "# DETECTION OBJE IN IMAGES\n",
        "image = cv2.imread('/content/dog-human.jpg')\n",
        "\n",
        "run_inference_Fall_Detection(image)\n",
        "    \n",
        "cv2_imshow(image)    \n",
        "cv2.imwrite(\"object-detection-output.jpg\", image)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#YENİ 0 1 LIST OLUŞTURMA\n",
        "endList = []\n",
        "for i in range(len(avgList) - 1):\n",
        "  if(avgList[i] < avgList[i + 1]):\n",
        "    endList.append(1)\n",
        "  else:\n",
        "    endList.append(0) "
      ],
      "metadata": {
        "id": "uWg2LWc0Z4vB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# frame'lerin oranına bakarak oluşturulan liste'nin üzerinde size=5 olan window gezdirerek yeni bir list oluşturuyorum. -> reduce etmek için gibi bir şey\n",
        "# 0 ve 1 lerı tekrar 0 ve 1 olarak reduce etme\n",
        "def sliding_window(liste): \n",
        "    \n",
        "    i = 0\n",
        "    t = 0\n",
        "    reduceList = []\n",
        "    temp = []\n",
        "    reduce_ones = 0\n",
        "    reduce_zeros = 0\n",
        "\n",
        "    print(liste)\n",
        "\n",
        "    if len(liste) == 5:\n",
        "        return liste\n",
        "    \n",
        "    for i in range(len(liste) - 5 + 1): #5 -> window size\n",
        "        \n",
        "      temp = liste[i: i+5] \n",
        "      print(temp)\n",
        "        \n",
        "      while t <= len(temp)-1:\n",
        "        \n",
        "        if (temp[t] == 1):\n",
        "          reduce_ones = reduce_ones + 1\n",
        "          t = t+1       \n",
        "        else:\n",
        "          reduce_zeros = reduce_zeros + 1\n",
        "          t = t+1       \n",
        "\n",
        "      if(reduce_ones > reduce_zeros):\n",
        "        reduceList.append(1)\n",
        "      if(reduce_zeros > reduce_ones):\n",
        "        reduceList.append(0)\n",
        "      \n",
        "      t = 0\n",
        "      reduce_ones = 0\n",
        "      reduce_zeros = 0\n",
        "\n",
        "    return reduceList\n",
        "         \n",
        "\n",
        "endList = sliding_window(resultsList)\n",
        "\n",
        "print(endList)\n",
        "\n"
      ],
      "metadata": {
        "id": "O0eiRA0sTpZq"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "yolov4_opencv_fall_detection.ipynb adlı not defterinin kopyası",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}